{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27fc78bf46efbdd",
   "metadata": {},
   "source": [
    "# Perform Node Classification on the WACV Dataset\n",
    "\n",
    "**Overview of the dataset**\n",
    "- The new dataset is in `./GraphPCB/Graph-W/graphs/` and `/home/lantian/GraphPCB/Graph-F/graphs/`\n",
    "- The nodes have 4 types/categories:\n",
    "    - 0-IC  the target\n",
    "    - 1-DT (hard to distinguish from 0-IC)\n",
    "    - 2-Diode (also hard to tell from 0-IC)\n",
    "    - 3-Others (everything else, should be easier to distinguish)\n",
    "- **Note that not all categories are presented in all the graphs (which means, there are some graphs that has less than 4 types of nodes)**\n",
    "\n",
    "**Graph-WACV**\n",
    "- The train/test sets contain 37/10 graphs each.\n",
    "- The stats of the graphs are like this:\n",
    "    - avg num of nodes in each graph are mostly around 50-600\n",
    "    - avg num of node degrees are between 5.7-5.9\n",
    "    - the diameter of the graph are a normal distribution centered at ~14\n",
    "\n",
    "**Plans**\n",
    "- Try some node classification that presents in this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4f37c6af28550a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T05:51:00.644027Z",
     "start_time": "2025-04-04T05:51:00.640061Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import shutil\n",
    "import random\n",
    "from utils import *\n",
    "from logger import PCB_Logger\n",
    "\n",
    "from collections import defaultdict\n",
    "from acmgnn.models import GCN\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch_geometric.utils import (\n",
    "        to_dense_adj,\n",
    "        contains_self_loops,\n",
    "        remove_self_loops,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61867aa08f8863",
   "metadata": {},
   "source": [
    "# Dataset Loader\n",
    "\n",
    "- Load GraphPCB graphs as DGLGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc30f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /home/lantian/GraphPCB_Analysis/GraphPCB\n"
     ]
    }
   ],
   "source": [
    "# Set the home directory for the dataset\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "dataset_dir = os.path.join(home_dir, \"GraphPCB_Analysis/GraphPCB\")\n",
    "print(\"Dataset directory:\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d65dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(config):\n",
    "    train_dir = os.path.join(config['dataset_dir'], f\"Graph-{config['dataset'][0].upper()}/graphs\", \"train\")\n",
    "    test_dir = os.path.join(config['dataset_dir'], f\"Graph-{config['dataset'][0].upper()}/graphs\", \"test\")\n",
    "    train_graphs = sorted(glob(f\"{train_dir}/*.pt\"))\n",
    "    test_graphs = sorted(glob(f\"{test_dir}/*.pt\"))\n",
    "    return train_graphs, test_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7604bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_our_data(graph_path, device):\n",
    "    \"\"\"\n",
    "    Load user's .pt graph file in PyG Data format and return\n",
    "    sparse normalized adjacency matrices (low/high frequency),\n",
    "    features, and labels.\n",
    "    \"\"\"\n",
    "    data = torch.load(graph_path, map_location=device)\n",
    "\n",
    "    x = data.x.to(device)  # Node features\n",
    "    y = data.y.to(device)  # Node labels\n",
    "    edge_index = data.edge_index.to(device)\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "\n",
    "    # Convert edge_index to dense adjacency\n",
    "    adj_dense = to_dense_adj(edge_index, max_num_nodes=num_nodes)[0]\n",
    "    adj_dense[adj_dense != 0] = 1\n",
    "    adj_dense.fill_diagonal_(0)\n",
    "\n",
    "    # Compute normalized low- and high-pass filters\n",
    "    adj_low = adj_dense + torch.eye(num_nodes, device=device)\n",
    "    deg = torch.sum(adj_low, dim=1)\n",
    "    deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "    norm = deg_inv_sqrt.unsqueeze(1) * adj_low * deg_inv_sqrt.unsqueeze(0)\n",
    "    adj_low = norm.to_sparse()\n",
    "    adj_high = (torch.eye(num_nodes, device=device) - norm).to_sparse()\n",
    "\n",
    "    return adj_low, adj_high, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d86f6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2488370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_graphs):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    predictions = []\n",
    "\n",
    "    for graph_path in test_graphs:\n",
    "        # get device fron model\n",
    "        device = next(model.parameters()).device\n",
    "        graph_file_name = os.path.basename(graph_path)\n",
    "        adj_low, adj_high, features, labels = load_our_data(graph_path, device)\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        adj_low, adj_high = adj_low.to(device), adj_high.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(features, adj_low, adj_high)\n",
    "            preds = output.max(1)[1]\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "        predictions.append({\n",
    "            \"graph_id\": graph_file_name,\n",
    "            \"labels\": preds.tolist()\n",
    "        })\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    return all_preds.numpy(), all_labels.numpy(), predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3fb9e4c45b200",
   "metadata": {},
   "source": [
    "# Training Function\n",
    "- for every 10 epoch, save the model and evaluate on test set\n",
    "- save the training log into a .txt\n",
    "- save the last checkpoint\n",
    "- save the predictions into a .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121ce760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, train_graphs, optimizer, scheduler, device):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, graph_path in enumerate(train_graphs):\n",
    "        adj_low, adj_high, features, labels = load_our_data(graph_path, device)\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        adj_low, adj_high = adj_low.to(device), adj_high.to(device)\n",
    "\n",
    "        logits = model(features, adj_low, adj_high)\n",
    "        loss = compute_loss(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_graphs)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23f72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function to train the model\n",
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Generic function to train different GNN models.\n",
    "    \"\"\"\n",
    "    set_seed(42)\n",
    "    train_graphs, test_graphs = get_data_loader(config)\n",
    "\n",
    "    logger = PCB_Logger(home_dir='/home/lantian/', config=config)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load first graph to init model\n",
    "    adj_low, adj_high, features, labels = load_our_data(train_graphs[0], config[\"device\"])\n",
    "    model = GCN(\n",
    "        nfeat=features.shape[1],\n",
    "        nhid=config[\"hidden_dim\"],\n",
    "        nclass=labels.max().item() + 1,\n",
    "        dropout=config[\"dropout\"],\n",
    "        model_type=config[\"model\"],\n",
    "    ).to(config[\"device\"])\n",
    "\n",
    "    \n",
    "    # ✅ Move model to device\n",
    "    model = model.to(config[\"device\"])\n",
    "    \n",
    "    # ✅ Define optimizer & scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"scheduler\"][\"step_size\"], gamma=config[\"scheduler\"][\"gamma\"])\n",
    "\n",
    "    # ✅ Training Loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        avg_loss = train_step(model, train_graphs, optimizer, scheduler, config[\"device\"])\n",
    "        logger.log(f\"Epoch {epoch + 1:03d}, Loss: {avg_loss:.10f}\")\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                print(f\"Parameter with requires_grad=False: {name}\")\n",
    "\n",
    "        # ✅ Evaluate every 10 epochs OR at the last epoch\n",
    "        if (epoch + 1) % 10 == 0 or (epoch + 1 == config[\"num_epochs\"]):\n",
    "            all_preds, all_labels, predictions = inference(model, test_graphs)\n",
    "            metrics = compute_metrics(all_preds, all_labels)\n",
    "            logger.update_metrics(metrics, predictions)\n",
    "    \n",
    "    logger.finish_run()\n",
    "    # save only the final model\n",
    "    checkpoint_path = os.path.join(logger.checkpoint_dir, f\"model_epoch_{epoch + 1}_{avg_loss:.4f}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'metrics': metrics,\n",
    "    }, checkpoint_path)\n",
    "    logger.log(f\"✅ Model checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "    return model, metrics, logger.checkpoint_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc9fdf5d227d34",
   "metadata": {},
   "source": [
    "# Config and Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59e7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic configuration \n",
    "config = {\n",
    "    \"experiment_name\": \"\",\n",
    "    \"dataset_dir\": dataset_dir,\n",
    "    \"home_dir\": home_dir,\n",
    "    \"dataset\": \"fpic\",\n",
    "    \"device\": \"cuda:0\",\n",
    "\n",
    "    # model architecture\n",
    "    \"model\": \"acmgcn\",\n",
    "    \"input_dim\": 1024,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"output_dim\": 4,\n",
    "\n",
    "    # regularization\n",
    "    \"dropout\": 0.3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"scheduler\": {\"type\": \"StepLR\", \"step_size\": 20, \"gamma\": 0.5},\n",
    "\n",
    "    # training parameters\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_epochs\": 200,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4df2024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory: /home/lantian/GraphPCB_Analysis/Graph-F-trained/ACMGNN-acmgcn_h256_0-NLL\n",
      "Experiment Configuration:\n",
      "experiment_name: ACMGNN-acmgcn_h256_0-NLL\n",
      "dataset_dir: /home/lantian/GraphPCB_Analysis/GraphPCB\n",
      "home_dir: /home/lantian\n",
      "dataset: fpic\n",
      "device: cuda:0\n",
      "model: acmgcn\n",
      "input_dim: 1024\n",
      "hidden_dim: 256\n",
      "output_dim: 4\n",
      "dropout: 0.5\n",
      "weight_decay: 0.01\n",
      "scheduler: {'type': 'StepLR', 'step_size': 20, 'gamma': 0.5}\n",
      "learning_rate: 0.0001\n",
      "num_epochs: 200\n",
      "Using device: cuda:0\n",
      "Loading dataset: fpic\n",
      "Results will be saved to /home/lantian/GraphPCB_Analysis/Graph-F-trained/ACMGNN-acmgcn_h256_0-NLL.\n",
      "Epoch 001, Loss: 1.2414564313\n",
      "Epoch 002, Loss: 1.0352419660\n",
      "Epoch 003, Loss: 0.8434374422\n",
      "Epoch 004, Loss: 0.7830112258\n",
      "Epoch 005, Loss: 0.7294144131\n",
      "Epoch 006, Loss: 0.6955002044\n",
      "Epoch 007, Loss: 0.7207780249\n",
      "Epoch 008, Loss: 0.6694758042\n",
      "Epoch 009, Loss: 0.6743271260\n",
      "Epoch 010, Loss: 0.6579381474\n",
      "  F1-Score (macro): 0.5298613004\n",
      "  Weighted F1: 0.9224893322\n",
      "  Subset F1-Score (3-class): 0.6522694204\n",
      "  F1 per class: [0.6782945736434108, 0.2637362637362637, 0.22127659574468087, 0.95613776861937]\n",
      "  Precision per class: [0.6055363321799307, 0.3076923076923077, 0.13333333333333333, 0.9857359635811836]\n",
      "  Recall per class: [0.7709251101321586, 0.23076923076923078, 0.65, 0.9282652186338954]\n",
      "  Confusion Matrix:\n",
      "[[175, 10, 14, 28], [7, 12, 25, 8], [2, 1, 26, 11], [105, 16, 130, 3248]]\n",
      "Epoch 011, Loss: 0.6437333499\n",
      "Epoch 012, Loss: 0.6387468451\n",
      "Epoch 013, Loss: 0.6386891028\n",
      "Epoch 014, Loss: 0.6155342936\n",
      "Epoch 015, Loss: 0.5970122988\n",
      "Epoch 016, Loss: 0.5953447945\n",
      "Epoch 017, Loss: 0.6087148328\n",
      "Epoch 018, Loss: 0.5895537864\n",
      "Epoch 019, Loss: 0.6031749666\n",
      "Epoch 020, Loss: 0.5619373911\n",
      "  F1-Score (macro): 0.5852010445\n",
      "  Weighted F1: 0.9312752381\n",
      "  Subset F1-Score (3-class): 0.7342792381\n",
      "  F1 per class: [0.69140625, 0.39316239316239315, 0.29411764705882354, 0.9621178879625566]\n",
      "  Precision per class: [0.6210526315789474, 0.35384615384615387, 0.19230769230769232, 0.9853205512282804]\n",
      "  Recall per class: [0.7797356828193832, 0.4423076923076923, 0.625, 0.9399828522434981]\n",
      "  Confusion Matrix:\n",
      "[[177, 14, 7, 29], [6, 23, 16, 7], [1, 1, 25, 13], [101, 27, 82, 3289]]\n",
      "Epoch 021, Loss: 0.5632842022\n",
      "Epoch 022, Loss: 0.5422984348\n",
      "Epoch 023, Loss: 0.5246459034\n",
      "Epoch 024, Loss: 0.5214395538\n",
      "Epoch 025, Loss: 0.5178887213\n",
      "Epoch 026, Loss: 0.5068142393\n",
      "Epoch 027, Loss: 0.5151768053\n",
      "Epoch 028, Loss: 0.4959446798\n",
      "Epoch 029, Loss: 0.5080155373\n",
      "Epoch 030, Loss: 0.5001935813\n",
      "  F1-Score (macro): 0.6325744669\n",
      "  Weighted F1: 0.9440516711\n",
      "  Subset F1-Score (3-class): 0.7459596916\n",
      "  F1 per class: [0.7201565557729941, 0.47058823529411764, 0.3673469387755102, 0.9722061378112333]\n",
      "  Precision per class: [0.647887323943662, 0.417910447761194, 0.3103448275862069, 0.9850396010560282]\n",
      "  Recall per class: [0.8105726872246696, 0.5384615384615384, 0.45, 0.9597027722206345]\n",
      "  Confusion Matrix:\n",
      "[[184, 12, 4, 27], [7, 28, 10, 7], [1, 4, 18, 17], [92, 23, 26, 3358]]\n",
      "Epoch 031, Loss: 0.4905038585\n",
      "Epoch 032, Loss: 0.5026562153\n",
      "Epoch 033, Loss: 0.4776479157\n",
      "Epoch 034, Loss: 0.5017344077\n",
      "Epoch 035, Loss: 0.4889384343\n",
      "Epoch 036, Loss: 0.4924843694\n",
      "Epoch 037, Loss: 0.4713059549\n",
      "Epoch 038, Loss: 0.4573045737\n",
      "Epoch 039, Loss: 0.4468197672\n",
      "Epoch 040, Loss: 0.4686766441\n",
      "  F1-Score (macro): 0.6554819124\n",
      "  Weighted F1: 0.9481292644\n",
      "  Subset F1-Score (3-class): 0.7785325256\n",
      "  F1 per class: [0.7554671968190856, 0.5378151260504201, 0.35514018691588783, 0.9735051397133343]\n",
      "  Precision per class: [0.6884057971014492, 0.47761194029850745, 0.2835820895522388, 0.9865023474178404]\n",
      "  Recall per class: [0.8370044052863436, 0.6153846153846154, 0.475, 0.960845955987425]\n",
      "  Confusion Matrix:\n",
      "[[190, 9, 3, 25], [5, 32, 9, 6], [1, 5, 19, 15], [80, 21, 36, 3362]]\n",
      "Epoch 041, Loss: 0.4654743329\n",
      "Epoch 042, Loss: 0.4557195034\n",
      "Epoch 043, Loss: 0.4240385830\n",
      "Epoch 044, Loss: 0.4503009633\n",
      "Epoch 045, Loss: 0.4506678190\n",
      "Epoch 046, Loss: 0.4435450066\n",
      "Epoch 047, Loss: 0.4463905707\n",
      "Epoch 048, Loss: 0.4284492454\n",
      "Epoch 049, Loss: 0.4257313575\n",
      "Epoch 050, Loss: 0.4214606200\n",
      "  F1-Score (macro): 0.6620923285\n",
      "  Weighted F1: 0.9494978389\n",
      "  Subset F1-Score (3-class): 0.7768120516\n",
      "  F1 per class: [0.7599243856332704, 0.5309734513274337, 0.3829787234042553, 0.9744927536231884]\n",
      "  Precision per class: [0.6655629139072847, 0.4918032786885246, 0.3333333333333333, 0.9885327844751544]\n",
      "  Recall per class: [0.8854625550660793, 0.5769230769230769, 0.45, 0.960845955987425]\n",
      "  Confusion Matrix:\n",
      "[[201, 8, 1, 17], [7, 30, 9, 6], [1, 5, 18, 16], [93, 18, 26, 3362]]\n",
      "Epoch 051, Loss: 0.4306156598\n",
      "Epoch 052, Loss: 0.4317532125\n",
      "Epoch 053, Loss: 0.4327425110\n",
      "Epoch 054, Loss: 0.4313254257\n",
      "Epoch 055, Loss: 0.4160643247\n",
      "Epoch 056, Loss: 0.4192189979\n",
      "Epoch 057, Loss: 0.4058009785\n",
      "Epoch 058, Loss: 0.4128326282\n",
      "Epoch 059, Loss: 0.4135278224\n",
      "Epoch 060, Loss: 0.4062688351\n",
      "  F1-Score (macro): 0.6503631046\n",
      "  Weighted F1: 0.9474656562\n",
      "  Subset F1-Score (3-class): 0.7758053955\n",
      "  F1 per class: [0.7604562737642585, 0.5045045045045046, 0.36363636363636365, 0.972855276527798]\n",
      "  Precision per class: [0.6688963210702341, 0.4745762711864407, 0.2857142857142857, 0.988495575221239]\n",
      "  Recall per class: [0.8810572687224669, 0.5384615384615384, 0.5, 0.9577022006287511]\n",
      "  Confusion Matrix:\n",
      "[[200, 6, 2, 19], [9, 28, 9, 6], [1, 5, 20, 14], [89, 20, 39, 3351]]\n",
      "Epoch 061, Loss: 0.4000775583\n",
      "Epoch 062, Loss: 0.4096510964\n",
      "Epoch 063, Loss: 0.3913138769\n",
      "Epoch 064, Loss: 0.4152704360\n",
      "Epoch 065, Loss: 0.3968395820\n",
      "Epoch 066, Loss: 0.4021386660\n",
      "Epoch 067, Loss: 0.4037193539\n",
      "Epoch 068, Loss: 0.4011825031\n",
      "Epoch 069, Loss: 0.3803976657\n",
      "Epoch 070, Loss: 0.3908736425\n",
      "  F1-Score (macro): 0.6486904423\n",
      "  Weighted F1: 0.9426882274\n",
      "  Subset F1-Score (3-class): 0.8059182903\n",
      "  F1 per class: [0.7522935779816513, 0.5045045045045046, 0.3698630136986301, 0.9681006731050628]\n",
      "  Precision per class: [0.6446540880503144, 0.4745762711864407, 0.25471698113207547, 0.991904047976012]\n",
      "  Recall per class: [0.9030837004405287, 0.5384615384615384, 0.675, 0.9454129751357531]\n",
      "  Confusion Matrix:\n",
      "[[205, 6, 2, 14], [10, 28, 11, 3], [1, 2, 27, 10], [102, 23, 66, 3308]]\n",
      "Epoch 071, Loss: 0.4076356008\n",
      "Epoch 072, Loss: 0.3958405276\n",
      "Epoch 073, Loss: 0.3934630987\n",
      "Epoch 074, Loss: 0.4064339893\n",
      "Epoch 075, Loss: 0.4031788530\n",
      "Epoch 076, Loss: 0.3976572459\n",
      "Epoch 077, Loss: 0.3809004735\n",
      "Epoch 078, Loss: 0.3873978300\n",
      "Epoch 079, Loss: 0.3709154382\n",
      "Epoch 080, Loss: 0.3928049814\n",
      "  F1-Score (macro): 0.6711155327\n",
      "  Weighted F1: 0.9488968276\n",
      "  Subset F1-Score (3-class): 0.7995977757\n",
      "  F1 per class: [0.7631578947368421, 0.5663716814159292, 0.38181818181818183, 0.9731143729109141]\n",
      "  Precision per class: [0.6655737704918033, 0.5245901639344263, 0.3, 0.989946777054997]\n",
      "  Recall per class: [0.8942731277533039, 0.6153846153846154, 0.525, 0.9568448128036582]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [7, 32, 11, 2], [1, 4, 21, 14], [94, 20, 37, 3348]]\n",
      "Epoch 081, Loss: 0.3839760762\n",
      "Epoch 082, Loss: 0.3716477992\n",
      "Epoch 083, Loss: 0.3828521892\n",
      "Epoch 084, Loss: 0.3669492706\n",
      "Epoch 085, Loss: 0.3721217094\n",
      "Epoch 086, Loss: 0.3874150594\n",
      "Epoch 087, Loss: 0.3780699780\n",
      "Epoch 088, Loss: 0.3828943624\n",
      "Epoch 089, Loss: 0.3691672231\n",
      "Epoch 090, Loss: 0.3741854751\n",
      "  F1-Score (macro): 0.6673618297\n",
      "  Weighted F1: 0.9467457654\n",
      "  Subset F1-Score (3-class): 0.8183800469\n",
      "  F1 per class: [0.7645951035781544, 0.5636363636363636, 0.37037037037037035, 0.9708454810495627]\n",
      "  Precision per class: [0.6677631578947368, 0.5344827586206896, 0.2631578947368421, 0.9907765545968462]\n",
      "  Recall per class: [0.8942731277533039, 0.5961538461538461, 0.625, 0.9517004858531009]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 2, 17], [8, 31, 11, 2], [1, 2, 25, 12], [92, 20, 57, 3330]]\n",
      "Epoch 091, Loss: 0.3759957094\n",
      "Epoch 092, Loss: 0.3832574652\n",
      "Epoch 093, Loss: 0.3941131346\n",
      "Epoch 094, Loss: 0.3791313275\n",
      "Epoch 095, Loss: 0.3936567439\n",
      "Epoch 096, Loss: 0.3906468030\n",
      "Epoch 097, Loss: 0.3671657488\n",
      "Epoch 098, Loss: 0.3694905337\n",
      "Epoch 099, Loss: 0.3819598323\n",
      "Epoch 100, Loss: 0.3770589292\n",
      "  F1-Score (macro): 0.6713244095\n",
      "  Weighted F1: 0.9479617357\n",
      "  Subset F1-Score (3-class): 0.8252757118\n",
      "  F1 per class: [0.7689393939393939, 0.5636363636363636, 0.380952380952381, 0.9717694994179278]\n",
      "  Precision per class: [0.6744186046511628, 0.5344827586206896, 0.27906976744186046, 0.9899199525644826]\n",
      "  Recall per class: [0.8942731277533039, 0.5961538461538461, 0.6, 0.9542726493283795]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 31, 10, 3], [1, 2, 24, 13], [89, 20, 51, 3339]]\n",
      "Epoch 101, Loss: 0.3769289838\n",
      "Epoch 102, Loss: 0.3770865968\n",
      "Epoch 103, Loss: 0.3748435020\n",
      "Epoch 104, Loss: 0.3687065242\n",
      "Epoch 105, Loss: 0.3745035985\n",
      "Epoch 106, Loss: 0.3819105821\n",
      "Epoch 107, Loss: 0.3963012408\n",
      "Epoch 108, Loss: 0.3755750151\n",
      "Epoch 109, Loss: 0.3727032432\n",
      "Epoch 110, Loss: 0.3545383177\n",
      "  F1-Score (macro): 0.6613432111\n",
      "  Weighted F1: 0.9463894332\n",
      "  Subset F1-Score (3-class): 0.8091425640\n",
      "  F1 per class: [0.7631578947368421, 0.5504587155963302, 0.3609022556390977, 0.970853978431944]\n",
      "  Precision per class: [0.6655737704918033, 0.5263157894736842, 0.25806451612903225, 0.9904846862920011]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.6, 0.9519862817947985]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 2, 17], [8, 30, 12, 2], [1, 2, 24, 13], [93, 20, 55, 3331]]\n",
      "Epoch 111, Loss: 0.3645820977\n",
      "Epoch 112, Loss: 0.3517526945\n",
      "Epoch 113, Loss: 0.3598795099\n",
      "Epoch 114, Loss: 0.3619190945\n",
      "Epoch 115, Loss: 0.3756294631\n",
      "Epoch 116, Loss: 0.3823998279\n",
      "Epoch 117, Loss: 0.3648123821\n",
      "Epoch 118, Loss: 0.3829590788\n",
      "Epoch 119, Loss: 0.3596353153\n",
      "Epoch 120, Loss: 0.3677519176\n",
      "  F1-Score (macro): 0.6654384699\n",
      "  Weighted F1: 0.9469473615\n",
      "  Subset F1-Score (3-class): 0.8087455241\n",
      "  F1 per class: [0.7617260787992496, 0.5636363636363636, 0.365079365079365, 0.9713120722295036]\n",
      "  Precision per class: [0.6633986928104575, 0.5344827586206896, 0.26744186046511625, 0.9902019002375297]\n",
      "  Recall per class: [0.8942731277533039, 0.5961538461538461, 0.575, 0.9531294655615891]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 31, 11, 2], [1, 3, 23, 13], [94, 19, 51, 3335]]\n",
      "Epoch 121, Loss: 0.3606800098\n",
      "Epoch 122, Loss: 0.3706997162\n",
      "Epoch 123, Loss: 0.3645103921\n",
      "Epoch 124, Loss: 0.3751173714\n",
      "Epoch 125, Loss: 0.3661718553\n",
      "Epoch 126, Loss: 0.3521440734\n",
      "Epoch 127, Loss: 0.3568304563\n",
      "Epoch 128, Loss: 0.3664790550\n",
      "Epoch 129, Loss: 0.3664536717\n",
      "Epoch 130, Loss: 0.3713978009\n",
      "  F1-Score (macro): 0.6629018695\n",
      "  Weighted F1: 0.9476353524\n",
      "  Subset F1-Score (3-class): 0.8002010531\n",
      "  F1 per class: [0.7703984819734344, 0.5517241379310345, 0.3577235772357724, 0.9717612809315865]\n",
      "  Precision per class: [0.6766666666666666, 0.5, 0.26506024096385544, 0.990210619994067]\n",
      "  Recall per class: [0.8942731277533039, 0.6153846153846154, 0.55, 0.9539868533866819]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [7, 32, 11, 2], [0, 5, 22, 13], [90, 22, 49, 3338]]\n",
      "Epoch 131, Loss: 0.3613974887\n",
      "Epoch 132, Loss: 0.3788485835\n",
      "Epoch 133, Loss: 0.3709637917\n",
      "Epoch 134, Loss: 0.3746376222\n",
      "Epoch 135, Loss: 0.3681293763\n",
      "Epoch 136, Loss: 0.3642054420\n",
      "Epoch 137, Loss: 0.3529535254\n",
      "Epoch 138, Loss: 0.3562667719\n",
      "Epoch 139, Loss: 0.3657412088\n",
      "Epoch 140, Loss: 0.3669265649\n",
      "  F1-Score (macro): 0.6612141257\n",
      "  Weighted F1: 0.9461515907\n",
      "  Subset F1-Score (3-class): 0.8100822816\n",
      "  F1 per class: [0.7617260787992496, 0.5420560747663552, 0.37037037037037035, 0.9707039790118059]\n",
      "  Precision per class: [0.6633986928104575, 0.5272727272727272, 0.2631578947368421, 0.9904818560380726]\n",
      "  Recall per class: [0.8942731277533039, 0.5576923076923077, 0.625, 0.9517004858531009]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [9, 29, 12, 2], [1, 2, 25, 12], [93, 19, 57, 3330]]\n",
      "Epoch 141, Loss: 0.3597919157\n",
      "Epoch 142, Loss: 0.3477846350\n",
      "Epoch 143, Loss: 0.3590224395\n",
      "Epoch 144, Loss: 0.3717795416\n",
      "Epoch 145, Loss: 0.3836692093\n",
      "Epoch 146, Loss: 0.3606255971\n",
      "Epoch 147, Loss: 0.3781459112\n",
      "Epoch 148, Loss: 0.3569407176\n",
      "Epoch 149, Loss: 0.3485159150\n",
      "Epoch 150, Loss: 0.3689160303\n",
      "  F1-Score (macro): 0.6602673896\n",
      "  Weighted F1: 0.9461589307\n",
      "  Subset F1-Score (3-class): 0.8091425640\n",
      "  F1 per class: [0.7645951035781544, 0.5555555555555555, 0.35036496350364965, 0.9705539358600583]\n",
      "  Precision per class: [0.6677631578947368, 0.5357142857142857, 0.24742268041237114, 0.9904790240999702]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.6, 0.9514146899114032]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 2, 17], [8, 30, 12, 2], [1, 2, 24, 13], [92, 19, 59, 3329]]\n",
      "Epoch 151, Loss: 0.3529042807\n",
      "Epoch 152, Loss: 0.3830344223\n",
      "Epoch 153, Loss: 0.3719184760\n",
      "Epoch 154, Loss: 0.3719994470\n",
      "Epoch 155, Loss: 0.3539014859\n",
      "Epoch 156, Loss: 0.3491398775\n",
      "Epoch 157, Loss: 0.3509040097\n",
      "Epoch 158, Loss: 0.3550458991\n",
      "Epoch 159, Loss: 0.3760143070\n",
      "Epoch 160, Loss: 0.3582907060\n",
      "  F1-Score (macro): 0.6554327735\n",
      "  Weighted F1: 0.9453140492\n",
      "  Subset F1-Score (3-class): 0.8014608629\n",
      "  F1 per class: [0.7602996254681648, 0.5454545454545454, 0.3458646616541353, 0.9701122612625747]\n",
      "  Precision per class: [0.6612377850162866, 0.5172413793103449, 0.24731182795698925, 0.9901785714285715]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.575, 0.950843098028008]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 30, 12, 2], [1, 3, 23, 13], [95, 20, 57, 3327]]\n",
      "Epoch 161, Loss: 0.3683376086\n",
      "Epoch 162, Loss: 0.3690496550\n",
      "Epoch 163, Loss: 0.3553518080\n",
      "Epoch 164, Loss: 0.3556889752\n",
      "Epoch 165, Loss: 0.3674572810\n",
      "Epoch 166, Loss: 0.3517015499\n",
      "Epoch 167, Loss: 0.3688447092\n",
      "Epoch 168, Loss: 0.3658268014\n",
      "Epoch 169, Loss: 0.3612920349\n",
      "Epoch 170, Loss: 0.3444539786\n",
      "  F1-Score (macro): 0.6551074237\n",
      "  Weighted F1: 0.9456817813\n",
      "  Subset F1-Score (3-class): 0.7987940029\n",
      "  F1 per class: [0.7631578947368421, 0.5357142857142857, 0.3511450381679389, 0.970412476315406]\n",
      "  Precision per class: [0.6655737704918033, 0.5, 0.25274725274725274, 0.9901844140392624]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.575, 0.9514146899114032]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 30, 12, 2], [0, 4, 23, 13], [94, 21, 55, 3329]]\n",
      "Epoch 171, Loss: 0.3662797422\n",
      "Epoch 172, Loss: 0.3614412609\n",
      "Epoch 173, Loss: 0.3670086683\n",
      "Epoch 174, Loss: 0.3502058650\n",
      "Epoch 175, Loss: 0.3800236878\n",
      "Epoch 176, Loss: 0.3664202057\n",
      "Epoch 177, Loss: 0.3604048210\n",
      "Epoch 178, Loss: 0.3608089662\n",
      "Epoch 179, Loss: 0.3650940700\n",
      "Epoch 180, Loss: 0.3644848293\n",
      "  F1-Score (macro): 0.6545072899\n",
      "  Weighted F1: 0.9457976820\n",
      "  Subset F1-Score (3-class): 0.7987940029\n",
      "  F1 per class: [0.7660377358490564, 0.5357142857142857, 0.3458646616541353, 0.970412476315406]\n",
      "  Precision per class: [0.66996699669967, 0.5, 0.24731182795698925, 0.9901844140392624]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.575, 0.9514146899114032]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 30, 12, 2], [0, 4, 23, 13], [92, 21, 57, 3329]]\n",
      "Epoch 181, Loss: 0.3632241144\n",
      "Epoch 182, Loss: 0.3622427250\n",
      "Epoch 183, Loss: 0.3616394733\n",
      "Epoch 184, Loss: 0.3582988013\n",
      "Epoch 185, Loss: 0.3607517828\n",
      "Epoch 186, Loss: 0.3715920604\n",
      "Epoch 187, Loss: 0.3638321800\n",
      "Epoch 188, Loss: 0.3609411670\n",
      "Epoch 189, Loss: 0.3657579304\n",
      "Epoch 190, Loss: 0.3413693690\n",
      "  F1-Score (macro): 0.6541091104\n",
      "  Weighted F1: 0.9455743643\n",
      "  Subset F1-Score (3-class): 0.7987940029\n",
      "  F1 per class: [0.7645951035781544, 0.5357142857142857, 0.3458646616541353, 0.9702623906705539]\n",
      "  Precision per class: [0.6677631578947368, 0.5, 0.24731182795698925, 0.9901814936030943]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.575, 0.9511288939697057]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 30, 12, 2], [0, 4, 23, 13], [93, 21, 57, 3328]]\n",
      "Epoch 191, Loss: 0.3638099497\n",
      "Epoch 192, Loss: 0.3541160515\n",
      "Epoch 193, Loss: 0.3630112160\n",
      "Epoch 194, Loss: 0.3557150676\n",
      "Epoch 195, Loss: 0.3624382160\n",
      "Epoch 196, Loss: 0.3700099426\n",
      "Epoch 197, Loss: 0.3660054851\n",
      "Epoch 198, Loss: 0.3613293309\n",
      "Epoch 199, Loss: 0.3588541618\n",
      "Epoch 200, Loss: 0.3752163657\n",
      "  F1-Score (macro): 0.6548016785\n",
      "  Weighted F1: 0.9457393609\n",
      "  Subset F1-Score (3-class): 0.7987940029\n",
      "  F1 per class: [0.7645951035781544, 0.5357142857142857, 0.34848484848484845, 0.970412476315406]\n",
      "  Precision per class: [0.6677631578947368, 0.5, 0.25, 0.9901844140392624]\n",
      "  Recall per class: [0.8942731277533039, 0.5769230769230769, 0.575, 0.9514146899114032]\n",
      "  Confusion Matrix:\n",
      "[[203, 5, 1, 18], [8, 30, 12, 2], [0, 4, 23, 13], [93, 21, 56, 3329]]\n",
      "✅ Predictions saved to /home/lantian/GraphPCB_Analysis/Graph-F-trained/ACMGNN-acmgcn_h256_0-NLL/predictions_final.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lantian//GraphPCB_Analysis/Graph-F-trained/MLP/predictions_final.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Set seed before training\u001b[39;00m\n\u001b[1;32m     21\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m model, metrics, checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     43\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m compute_metrics(all_preds, all_labels)\n\u001b[1;32m     44\u001b[0m         logger\u001b[38;5;241m.\u001b[39mupdate_metrics(metrics, predictions)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# save only the final model\u001b[39;00m\n\u001b[1;32m     48\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(logger\u001b[38;5;241m.\u001b[39mcheckpoint_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GraphPCB_Analysis/logger.py:112\u001b[0m, in \u001b[0;36mPCB_Logger.finish_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_predictions()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     pod_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_pod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall POD: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pod_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_pod\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage POD per graph: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(pod_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpod_per_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(pod_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpod_per_label\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "File \u001b[0;32m~/GraphPCB_Analysis/logger.py:57\u001b[0m, in \u001b[0;36mPCB_Logger.calculate_pod\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Load predictions from JSON files\u001b[39;00m\n\u001b[1;32m     56\u001b[0m mlp_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhome_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/GraphPCB_Analysis/Graph-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-trained/MLP/predictions_final.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmlp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     58\u001b[0m     mlp_predictions \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     60\u001b[0m gnn_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lantian//GraphPCB_Analysis/Graph-F-trained/MLP/predictions_final.json'"
     ]
    }
   ],
   "source": [
    "run_num = 0\n",
    "\n",
    "config.update({\n",
    "    \"dataset\": \"fpic\",\n",
    "\n",
    "    # model architecture\n",
    "    \"model\": \"acmgcn\",\n",
    "    \"hidden_dim\": 256,\n",
    "    # regularization\n",
    "    \"dropout\": 0.5,\n",
    "    \"weight_decay\": 1e-2,\n",
    "\n",
    "    # training parameters\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_epochs\": 200,\n",
    "})\n",
    "\n",
    "config[\"experiment_name\"] = f\"ACMGNN-{config['model']}_h{config['hidden_dim']}_{run_num}-NLL\"\n",
    "\n",
    "# Set seed before training\n",
    "set_seed(42)\n",
    "\n",
    "model, metrics, checkpoint_dir = train_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b3b1e",
   "metadata": {},
   "source": [
    "# Run Multiple\n",
    "- Run multiple experiments for all the settings\n",
    "    - `model` = `acmgcn` or `acmsgc`\n",
    "    - `hidden_dim` from 64 to 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3e5988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory: /home/lantian/PCB_Analysis/FPIC-trained/FPIC_acmcgn_h64\n",
      "Experiment Configuration:\n",
      "experiment_name: FPIC_acmcgn_h64\n",
      "dataset_dir: /home/lantian/GraphPCB/\n",
      "home_dir: /home/lantian/\n",
      "dataset: FPIC\n",
      "device: cuda:0\n",
      "model: acmcgn\n",
      "input_dim: 1024\n",
      "hidden_dim: 64\n",
      "output_dim: 4\n",
      "dropout: 0.5\n",
      "weight_decay: 0.01\n",
      "scheduler: {'type': 'StepLR', 'step_size': 20, 'gamma': 0.5}\n",
      "learning_rate: 0.0001\n",
      "num_epochs: 200\n",
      "Using device: cuda:0\n",
      "Loading dataset: FPIC\n",
      "Results will be saved to /home/lantian/PCB_Analysis/FPIC-trained/FPIC_acmcgn_h64.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m config\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_variant,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_dim,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_variant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m })\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model with the updated config\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model, metrics, checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ✅ Define optimizer & scheduler\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], gamma\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# ✅ Training Loop\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch/optim/optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    277\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "# Define the settings to iterate over\n",
    "dataset_variants = ['FPIC', 'WACV']\n",
    "model_variants = ['acmcgn', 'acmsgc']\n",
    "hidden_dims = [64, 128, 256]\n",
    "\n",
    "# Iterate over the settings\n",
    "for dataset in dataset_variants:\n",
    "    for model_variant in model_variants:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            # Update the config with the current settings\n",
    "            config.update({\n",
    "                \"dataset\": dataset,\n",
    "                \"model\": model_variant,\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"experiment_name\": f\"{dataset}_{model_variant}_h{hidden_dim}\",\n",
    "            })\n",
    "\n",
    "            # Train the model with the updated config\n",
    "            model, metrics, checkpoint_dir = train_model(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ceff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
